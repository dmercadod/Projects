{"cells":[{"cell_type":"markdown","source":["<p style=\"text-align: center;\"><strong>MACHINE LEARNING</strong></p>\n","<p style=\"text-align: center;\"><br /> </p>\n","<p style=\"text-align: center;\"><strong>GRUPO 203008067_3</strong></p>\n","<p style=\"text-align: center;\"><br /> </p>\n","<p style=\"text-align: center;\"><strong>FASE 3 - COMPONENTE PRACTICO - PRACTICAS SIMULADAS</strong></p>\n","<p style=\"text-align: center;\"><br /> </p>\n","<p style=\"text-align: center;\"><strong>PRESENTADO POR: DARWIN RAUL MERCADO DIAZ</strong></p>\n","<p style=\"text-align: center;\"><br /> </p>\n","<p style=\"text-align: center;\"><strong>PRESENTADO A: EDGAR ANDRES VILLABON</strong></p>\n","<p style=\"text-align: center;\"><br /> <br /> </p>\n","<p style=\"text-align: center;\"><strong>UNIVERSIDAD ABIERTA Y A DISTANCIA UNAD</strong></p>\n","<p style=\"text-align: center;\"><br /> <br /> <br /> </p>\n","<p style=\"text-align: center;\"><strong>A&Ntilde;O 2023 II PERIODO 16-04</strong></p>\n","<p style=\"text-align: center;\">&nbsp;</p>"],"metadata":{"id":"yes927gldN27"},"id":"yes927gldN27"},{"cell_type":"markdown","source":["# **Ejercicio número 2 punto b**\n"," **Acción 2: Construcción de modelos lineales.**\n","\n","  - b. Usar la regresión logística para predecir la probabilidad de que un circuito tenga\n","una suspensión."],"metadata":{"id":"8Nhc3OCpQQU1"},"id":"8Nhc3OCpQQU1"},{"cell_type":"markdown","source":["- ***Desarrollo del modelo de regresión logística***"],"metadata":{"id":"y0TOVXXfQcG-"},"id":"y0TOVXXfQcG-"},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report"],"metadata":{"id":"ls2XaW2zPDYY"},"id":"ls2XaW2zPDYY","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cargar el conjunto de datos\n","df = pd.read_excel(\"Anexo 1 - evaluar las interrupciones del servicio de acueducto de EPM.xlsx\", header=1)"],"metadata":{"id":"1Xx1f2CzPDWE"},"id":"1Xx1f2CzPDWE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se eliminan las filas con valores nulos\n","df = df.dropna()"],"metadata":{"id":"ruGymHDRPDTo"},"id":"ruGymHDRPDTo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mapear \"Medio\" a \"Alto\" en la columna \"Impacto\"\n","df[\"Impacto\"] = df[\"Impacto\"].map({\"Bajo\": 0, \"Medio\": 1, \"Alto\": 2})"],"metadata":{"id":"vpuuhPvnPDQz"},"id":"vpuuhPvnPDQz","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Se seleccionan las variables X y y\n","X = df[[\"Impacto\"]]\n","y = df[\"Circuito\"]"],"metadata":{"id":"YaxNmwp3PDFG"},"id":"YaxNmwp3PDFG","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Codificar la variable objetivo (y) usando LabelEncoder\n","from sklearn.preprocessing import LabelEncoder\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)"],"metadata":{"id":"CyaqInlyPOIh"},"id":"CyaqInlyPOIh","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"],"metadata":{"id":"vQLBQN0wPOGA"},"id":"vQLBQN0wPOGA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Entrenar un modelo de regresión logística\n","logistic_reg = LogisticRegression(max_iter=1000)\n","logistic_reg.fit(X_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"bj8jsNO8PODj","executionInfo":{"status":"ok","timestamp":1698193894369,"user_tz":300,"elapsed":260,"user":{"displayName":"Darwin","userId":"08354179943003436911"}},"outputId":"5d68c592-03a7-4dfe-bc42-09b712e6d17c"},"id":"bj8jsNO8PODj","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(max_iter=1000)"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Realizar predicciones en el conjunto de prueba\n","y_pred = logistic_reg.predict(X_test)"],"metadata":{"id":"SMYGgENaPN7a"},"id":"SMYGgENaPN7a","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calcular la precisión del modelo\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Precisión del modelo de regresión logística: {accuracy:.2f}\")\n","\n","# Mostrar un informe de clasificación\n","report = classification_report(y_test, y_pred, zero_division=1)\n","print(report)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvzQOsZpPS-b","executionInfo":{"status":"ok","timestamp":1698193897476,"user_tz":300,"elapsed":5,"user":{"displayName":"Darwin","userId":"08354179943003436911"}},"outputId":"5941d923-ecfb-4a7f-d129-e4d2f8a0e5e7"},"id":"uvzQOsZpPS-b","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Precisión del modelo de regresión logística: 0.04\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.00      0.00         3\n","           1       1.00      0.00      0.00         2\n","           2       1.00      0.00      0.00         2\n","           3       1.00      0.00      0.00         1\n","           6       1.00      0.00      0.00         1\n","           8       1.00      0.00      0.00         3\n","           9       1.00      0.00      0.00         1\n","          10       1.00      0.00      0.00         3\n","          11       1.00      0.00      0.00         3\n","          12       1.00      0.00      0.00         1\n","          14       1.00      0.00      0.00         1\n","          15       1.00      0.00      0.00         4\n","          16       0.12      0.12      0.12         8\n","          17       1.00      0.00      0.00         4\n","          18       1.00      0.00      0.00         2\n","          19       1.00      0.00      0.00         5\n","          20       1.00      0.00      0.00         3\n","          22       1.00      0.00      0.00         1\n","          24       1.00      0.00      0.00         1\n","          25       1.00      0.00      0.00         1\n","          28       1.00      0.00      0.00         1\n","          29       1.00      0.00      0.00         2\n","          30       1.00      0.00      0.00         2\n","          31       1.00      0.00      0.00         4\n","          32       1.00      0.00      0.00         3\n","          33       1.00      0.00      0.00         1\n","          34       1.00      0.00      0.00         1\n","          35       1.00      0.00      0.00         1\n","          38       1.00      0.00      0.00         2\n","          39       1.00      0.00      0.00         1\n","          40       1.00      0.00      0.00         1\n","          41       1.00      0.00      0.00         2\n","          42       1.00      0.00      0.00         1\n","          43       1.00      0.00      0.00         1\n","          44       1.00      0.00      0.00         4\n","          45       1.00      0.00      0.00         3\n","          46       1.00      0.00      0.00         1\n","          48       0.03      1.00      0.05         2\n","          51       1.00      0.00      0.00         1\n","          52       1.00      0.00      0.00         3\n","          53       1.00      0.00      0.00         2\n","          54       1.00      0.00      0.00         2\n","          55       1.00      0.00      0.00         3\n","          56       1.00      0.00      0.00         1\n","          57       1.00      0.00      0.00         3\n","          60       1.00      0.00      0.00         1\n","          61       1.00      0.00      0.00         2\n","          62       1.00      0.00      0.00         3\n","          63       1.00      0.00      0.00         3\n","          64       1.00      0.00      0.00         2\n","          65       1.00      0.00      0.00         2\n","          68       1.00      0.00      0.00         2\n","          69       1.00      0.00      0.00         2\n","          70       1.00      0.00      0.00         1\n","          71       1.00      0.00      0.00         3\n","          72       1.00      0.00      0.00        11\n","          73       1.00      0.00      0.00         2\n","          74       1.00      0.00      0.00         4\n","          75       1.00      0.00      0.00         1\n","          76       1.00      0.00      0.00         1\n","          77       1.00      0.00      0.00         1\n","          78       1.00      0.00      0.00         1\n","          79       1.00      0.00      0.00         2\n","          80       1.00      0.00      0.00         2\n","          81       1.00      0.00      0.00         1\n","          82       1.00      0.00      0.00         3\n","          83       1.00      0.00      0.00         3\n","          84       1.00      0.00      0.00         4\n","          87       1.00      0.00      0.00         1\n","          88       1.00      0.00      0.00         1\n","          89       1.00      0.00      0.00         1\n","          90       1.00      0.00      0.00         4\n","          91       1.00      0.00      0.00         2\n","          93       1.00      0.00      0.00         2\n","          96       1.00      0.00      0.00         5\n","          97       1.00      0.00      0.00         1\n","          98       1.00      0.00      0.00         2\n","          99       1.00      0.00      0.00         1\n","         101       1.00      0.00      0.00         2\n","         102       1.00      0.00      0.00         1\n","         103       1.00      0.00      0.00         1\n","         104       1.00      0.00      0.00         1\n","         107       1.00      0.00      0.00         2\n","         108       0.04      0.80      0.07         5\n","         109       1.00      0.00      0.00         1\n","         110       1.00      0.00      0.00         3\n","\n","    accuracy                           0.04       191\n","   macro avg       0.97      0.02      0.00       191\n","weighted avg       0.93      0.04      0.01       191\n","\n"]}]},{"cell_type":"markdown","source":["***La precisión obtenida es muy baja, por lo tanto se espera que las predicciones desarrolladas por el modelo no sean efectivas, esto puede ser dado las variables que se están utilizando para realizar el modelo de regresión lineal***"],"metadata":{"id":"raFo9brqQ8kc"},"id":"raFo9brqQ8kc"},{"cell_type":"code","source":["# Realizar predicciones para todos los datos\n","probabilidades_suspension = logistic_reg.predict_proba(X)[:, 1]"],"metadata":{"id":"vUJejDqVPS73"},"id":"vUJejDqVPS73","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Agregar las probabilidades al DataFrame original\n","df[\"Probabilidad de Suspensión\"] = probabilidades_suspension\n","\n","# Mostrar el DataFrame con las probabilidades\n","print(df[[\"Circuito\", \"Probabilidad de Suspensión\"]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zZe3uTJwPS5h","executionInfo":{"status":"ok","timestamp":1698193916065,"user_tz":300,"elapsed":4,"user":{"displayName":"Darwin","userId":"08354179943003436911"}},"outputId":"ac534eeb-36a3-43b4-beda-bdeb6a728bd3"},"id":"zZe3uTJwPS5h","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["           Circuito  Probabilidad de Suspensión\n","0     San Cristóbal                    0.015866\n","1     San Cristóbal                    0.015866\n","2    Castilla-Bello                    0.015866\n","3       Aguas Frías                    0.015866\n","4       Aguas Frías                    0.015866\n","..              ...                         ...\n","956           Bello                    0.015866\n","957  Santa Catalina                    0.001442\n","958        El Noral                    0.015866\n","959   Santo Domingo                    0.001442\n","960       El Chocho                    0.015866\n","\n","[953 rows x 2 columns]\n"]}]},{"cell_type":"markdown","source":["***Tal como se solicitó se entrega un nuevo DataFrame con las probabilidades de suspensión de los circuitos***"],"metadata":{"id":"5TZ8XtAARMOL"},"id":"5TZ8XtAARMOL"},{"cell_type":"markdown","source":["# **REFERENCIAS**\n","- Raschka, S., & Mirjalili, V. (2017). Python Machine Learning - Second Edition: Vol. 2nd ed. Packt Publishing. https://bibliotecavirtual.unad.edu.co/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=nlebk&AN=1606531&lang=es&site=eds-live&scope=site&ebv=EB&ppid=pp_60\n","\n","- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n","- https://devdocs.io/scikit_learn/\n","- Kane, F. (2017). Hands-On Data Science and Python Machine Learning. Packt Publishing. https://bibliotecavirtual.unad.edu.co/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=nlebk&AN=1566405&lang=es&site=eds-live&scope=site&ebv=EB&ppid=pp_133\n"],"metadata":{"id":"611IF62wSQwN"},"id":"611IF62wSQwN"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}